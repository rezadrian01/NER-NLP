# Wayang Stories NER & Knowledge Graph System

A comprehensive NLP system for Indonesian Wayang stories featuring Named Entity Recognition (NER) model evaluation and interactive knowledge graph visualization. The system compares spaCy's multilingual model against a custom-trained domain-specific model, then extracts and visualizes entity relationships using multiple relation extraction methods.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CSV Stories â†’ Annotations â†’ NER Training â†’ Custom Model    â”‚
â”‚       â”‚                                         â”‚            â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚            â”‚
â”‚                       â–¼                        â–¼            â”‚
â”‚              Knowledge Graph Builder                        â”‚
â”‚              â€¢ Regex (42 patterns)                          â”‚
â”‚              â€¢ Dependency Parsing                           â”‚
â”‚              â€¢ Co-occurrence Stats                          â”‚
â”‚                       â”‚                                     â”‚
â”‚                       â–¼                                     â”‚
â”‚        Interactive Visualization (96 entities, 94 edges)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ”— Quick Links:**
- ï¿½ [Quick Start Guide](QUICKSTART.md) - One command to run everything
- ï¿½ğŸ“Š [NER Evaluation Results](docs/NER_EVALUATION_SUMMARY.md)
- ğŸ•¸ï¸ [Knowledge Graph Relations](docs/KNOWLEDGE_GRAPH_RELATIONS.md)
- ğŸ—ï¸ [System Architecture](docs/ARCHITECTURE.md)
- ğŸ“ [Architecture Diagrams](docs/architecture.drawio)
- ğŸ“ [Project Structure](docs/PROJECT_STRUCTURE.md)
- ğŸ§¹ [Cleanup Summary](docs/CLEANUP_SUMMARY.md)

## ğŸ† Results

### NER Model Performance

The **Custom Trained Model** significantly outperforms the baseline:

| Metric | spaCy Multilingual | Custom Trained | Improvement |
|--------|-------------------|----------------|-------------|
| **Exact Match F1** | 0.00% | **23.08%** | +23.08% |
| **Partial Match F1** | 3.92% | **94.34%** | +90.42% |
| **Micro F1** | 0.00% | **18.60%** | +18.60% |

ğŸ“„ View full results: [`docs/NER_EVALUATION_SUMMARY.md`](docs/NER_EVALUATION_SUMMARY.md)

### Knowledge Graph Extraction

From 45 manually annotated examples:

| Metric | Count | Details |
|--------|-------|---------|
| **Total Entities** | 96 | 68 PERSON, 21 LOC, 5 ORG, 2 EVENT |
| **Total Relations** | 94 | 683% improvement from baseline |
| **Graph Density** | 0.0103 | Well-connected network |
| **Top Relation** | berinteraksi_dengan | 54 instances (social interactions) |

**Relation Extraction Methods:**
- ğŸ”¤ **Regex Patterns** (42 patterns) - Indonesian keywords
- ğŸŒ³ **Dependency Parsing** - Syntactic analysis with spaCy
- ğŸ“Š **Co-occurrence Statistics** - Entity proximity signals

ğŸ•¸ï¸ View interactive graph: `output/knowledge_graph.html`  
ğŸ“– Method details: [`docs/KNOWLEDGE_GRAPH_RELATIONS.md`](docs/KNOWLEDGE_GRAPH_RELATIONS.md)

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ scripts/                        # Data preparation
â”‚   â”œâ”€â”€ manual_annotations.py       # 45 annotated examples
â”‚   â””â”€â”€ create_manual_training_data.py
â”‚
â”œâ”€â”€ evaluation/                     # NER evaluation system
â”‚   â”œâ”€â”€ ner_trainer.py              # Train custom model
â”‚   â”œâ”€â”€ ner_evaluator.py            # Calculate metrics
â”‚   â””â”€â”€ compare_ner_models.py       # Compare models
â”‚
â”œâ”€â”€ tools/                          # Helper utilities
â”‚   â””â”€â”€ annotate_helper.py          # Annotation assistant
â”‚
â”œâ”€â”€ models/                         # Trained models & data
â”‚   â”œâ”€â”€ train_data.json             # 36 training examples
â”‚   â”œâ”€â”€ test_data.json              # 9 test examples
â”‚   â”œâ”€â”€ full_data.json              # All 45 examples
â”‚   â””â”€â”€ custom_ner_model/           # Trained model
â”‚
â”œâ”€â”€ output/                         # Generated outputs
â”‚   â”œâ”€â”€ ner_evaluation_comparison.json
â”‚   â”œâ”€â”€ ner_evaluation_comparison.html
â”‚   â”œâ”€â”€ knowledge_graph.json        # Graph data
â”‚   â””â”€â”€ knowledge_graph.html        # Interactive viz
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md             # System architecture
â”‚   â”œâ”€â”€ architecture.drawio         # Architecture diagrams
â”‚   â”œâ”€â”€ KNOWLEDGE_GRAPH_RELATIONS.md
â”‚   â”œâ”€â”€ NER_EVALUATION_SUMMARY.md
â”‚   â”œâ”€â”€ NER_EVALUATION_FINAL_RESULTS.md
â”‚   â”œâ”€â”€ HOW_TO_EXPAND_ANNOTATIONS.md
â”‚   â””â”€â”€ NER_EVALUATION.md
â”‚
â”œâ”€â”€ archived/                       # Old/unused files
â”œâ”€â”€ data/                           # Source datasets
â”œâ”€â”€ build_knowledge_graph.py        # KG builder
â”œâ”€â”€ run_ner_evaluation.py           # NER workflow
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

### One-Command Setup & Execution

The easiest way to run the entire pipeline:

```bash
./run_all.sh
```

This **automated script** will:
- âœ… Setup virtual environment (creates if not exists)
- âœ… Install all dependencies including spaCy model
- âœ… Train custom NER model (30 iterations)
- âœ… Evaluate and compare with baseline model
- âœ… Build knowledge graph with 3 extraction methods
- âœ… Generate interactive visualizations
- âœ… Display results summary with file locations

**ğŸ“– For detailed usage, troubleshooting, and manual steps, see:** [`QUICKSTART.md`](QUICKSTART.md)

### Results Location

After running the script, find your results here:
- **Knowledge Graph**: `output/knowledge_graph.html` (96 entities, 94 relations)
- **NER Evaluation**: `output/ner_evaluation_comparison.html` (model comparison)
- **Execution Log**: `output/pipeline_execution.log` (detailed logs)
- **Trained Model**: `models/custom_ner_model/` (custom weights)

### Manual Step-by-Step (Alternative)

If you prefer manual control, follow these steps:

<details>
<summary>Click to expand manual setup instructions</summary>

#### 1. Setup Environment

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download spaCy multilingual model
python -m spacy download xx_ent_wiki_sm
```

#### 2. Train NER Model

```bash
python3 ner_trainer.py
```

#### 3. Evaluate Models

```bash
python3 compare_ner_models.py
```

#### 4. Build Knowledge Graph

```bash
python3 build_knowledge_graph.py
```

#### 5. View Results

```bash
# Open interactive HTML report
xdg-open output/ner_evaluation_comparison.html
xdg-open output/knowledge_graph.html
```

</details>

## âœ¨ Features

### 1. Knowledge Graph Visualization
- **Interactive Network**: Explore entity relationships through physics-based graph layout
- **Entity Types**: Color-coded PERSON (blue), LOC (teal), ORG (orange), EVENT (red)
- **Relation Categories**: Family (pink), Conflict (red), Location (cyan), Participation (green)
- **Smart Sizing**: Node size reflects connectivity; edge width shows relation frequency
- **Rich Interactions**: Hover tooltips, zoom, pan, navigation controls
- **Full Dataset**: Visualizes all 45 manually annotated examples

### 2. Multi-Method Relation Extraction
- **Regex Patterns**: 42 Indonesian language patterns for explicit relations
- **Dependency Parsing**: Syntactic analysis using spaCy for implicit relations
- **Co-occurrence Statistics**: Entity proximity signals for social interactions

### 3. Dual Model Evaluation
- Compare custom-trained vs multilingual baseline models
- Detailed per-entity performance metrics
- Interactive HTML reports with visualizations

## ğŸ“Š Knowledge Graph Statistics

From the 45 manually annotated Wayang stories:
- **96 Total Entities**: 68 PERSON, 21 LOC, 5 ORG, 2 EVENT
- **94 Relations Extracted**: Social (54), Location (17), Family (8), etc.
- **Graph Density**: 0.0103 (683% improvement from baseline)
- **Top Relation**: berinteraksi_dengan (54 instances)

## ğŸ“Š Entity Types

The model recognizes four entity types:

- **PERSON** - Character names (Raden Arjuna, Prabu Kresna)
- **LOC** - Locations (Kerajaan Dwarawati, Kahyangan Suralaya)
- **ORG** - Organizations (Pandawa, Kurawa)
- **EVENT** - Named events (Perang Bharatayudha)

## ğŸ› ï¸ Manual Steps

### Build Knowledge Graph Only

```bash
python3 build_knowledge_graph.py
```

Outputs:
- `output/knowledge_graph.html` - Interactive visualization
- `output/knowledge_graph.json` - Graph data export

### Train Model Only

```bash
python3 evaluation/ner_trainer.py
```

### Compare Models Only

```bash
python3 evaluation/compare_ner_models.py
```

### Add More Annotations

```bash
# Use helper tool
python3 tools/annotate_helper.py

# Or use batch mode
python3 tools/annotate_helper.py --batch

# Edit annotations
nano scripts/manual_annotations.py

# Re-run workflow
python3 run_ner_evaluation.py
```

ğŸ“– See: `docs/HOW_TO_EXPAND_ANNOTATIONS.md`

## ğŸ“ˆ Training Data

- **Current:** 45 manually annotated sentences
- **Training:** 36 examples (80%)
- **Testing:** 9 examples (20%)
- **Entities:** 122 total (PERSON: 81, LOC: 24, ORG: 14, EVENT: 3)

### Sample Annotation

```python
(
    "Prabu Kresna memerintah di Kerajaan Dwarawati.",
    [(0, 12, 'PERSON'), (27, 45, 'LOC')]
),
```

## ğŸ¯ Key Findings

1. âœ… **Domain-specific training works** - Custom model achieves 23.08% F1 vs 0.00% baseline
2. âœ… **Excellent boundary detection** - 94.34% Partial Match F1
3. âœ… **Manual annotations effective** - High-quality labels produce good results
4. âš ï¸ **Need more data** - Current 45 examples prove concept; target 200+ for production

## ğŸ“š Documentation

- **NER_EVALUATION_SUMMARY.md** - Complete overview and quick reference
- **NER_EVALUATION_FINAL_RESULTS.md** - Detailed analysis with examples
- **HOW_TO_EXPAND_ANNOTATIONS.md** - Guide to add more training data
- **NER_EVALUATION.md** - Technical documentation

## ğŸ”§ Technical Details

**Custom Model:**
- Base: `xx_ent_wiki_sm` (spaCy multilingual)
- Method: Transfer learning
- Training: 30 iterations, batch size 8, dropout 0.2
- Final loss: 0.0105

**Metrics:**
- Exact Match (entity-level)
- Partial Match (token-level)
- Per-label F1 scores
- Macro/Micro F1
- Confusion matrices

## ğŸ—ï¸ Architecture

This system uses a three-layer architecture combining NER evaluation, knowledge graph construction, and interactive visualization. 

**Key Components:**
1. **Annotation Layer** - Manual entity labeling (45 examples)
2. **NER Pipeline** - Training & evaluation with spaCy
3. **Knowledge Graph** - Multi-method relation extraction (Regex, Dependency Parsing, Co-occurrence)

**System Flow:**
```
CSV Stories â†’ Annotations â†’ Train/Test Split â†’ NER Training â†’ Model Evaluation
                                    â†“
                            full_data.json â†’ Knowledge Graph Builder â†’ Interactive Viz
```

ğŸ“ **For detailed architecture documentation:**
- [`docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md) - Complete system architecture with diagrams
- [`docs/architecture.drawio`](docs/architecture.drawio) - Editable diagrams (open with [draw.io](https://app.diagrams.net))

**Technologies:**
- **NLP**: spaCy 3.x (NER training & parsing)
- **Graph**: NetworkX (structure) + PyVis (visualization)
- **Data**: JSON (serialization), Pandas (manipulation)

## ğŸ“ Next Steps

- [ ] Expand to 100+ annotated examples
- [ ] Add more LOC/ORG entity examples
- [ ] Re-train with larger dataset
- [ ] Target 0.70+ F1 for production

## ğŸ‘¤ Author

Kelompok 1  
NLP Final Assignment - November 2025

**Members:**
1. Achmad Mirzaram Dhani
2. Afito Indra Permana
3. Ahmad Reza Adrian
4. Ahmad Wildan Putro Santoso

## ğŸ“„ License

See LICENSE file
